{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import re, string, unicodedata\n",
    "import inflect\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mwizasimbeye/anaconda3/envs/dlr/lib/nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Data preprocessing, our data is in .doc and docx format. We need to convert the files to .txt to enable easy preprocessing.\n",
    "The mothod convert_resume() reads all the resumes in a provided folder. Note: The prepocessor uses a Mac tool called **textutil**. For linux users, please use **pandoc**. example: *pandoc -s example.docx -o output.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our method.\n",
    "def convert_resumes(path):\n",
    "    dirs = [os.path.join(path, o) for o in os.listdir(path) if os.path.isdir(os.path.join(path,o))]\n",
    "    for x in dirs:\n",
    "        x = x.replace(\" \", \"\\ \")\n",
    "        os.system('textutil -convert txt '+ x +'/*.doc*')\n",
    "    return \"Converted files to .txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess the resume. \n",
    "def process_resume(filename):\n",
    "    # load text\n",
    "    file = open(filename, 'rt')\n",
    "    text = file.read()\n",
    "    text = ' '.join(text.split()) # Remove double spaces\n",
    "    file.close()\n",
    "    # Remove the common hex values from text.\n",
    "    text = text.replace(\"\\xe2\", \"\").replace(\"\\x80\", \"\").replace(\"\\x93\", \"\").replace(\"\\x99\", \"\").replace(\"0x9c\", \"\")\n",
    "    text = text.lower()    \n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(words):\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data & create dataframe\n",
    "After the data has been read, we need to create a data frame of all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job titles & candidate name\n",
    "path = 'data/'\n",
    "col_names =  ['candidate_name', 'job_title', 'resume']\n",
    "data  = pd.DataFrame(columns = col_names)\n",
    "dirs = [os.path.join(path, o) for o in os.listdir(path) if os.path.isdir(os.path.join(path,o))]\n",
    "for x in dirs:\n",
    "    job = (x.replace('data/', ''))\n",
    "    files = [f for f in listdir(x) if isfile(join(x, f))]\n",
    "    candidates = [f for f in files if f.endswith('.txt') if f!=\"Success.txt\" if f!=\"Job Description.txt\"]\n",
    "    for x in candidates:\n",
    "        resume = process_resume(path+\"/\"+job+\"/\"+x).split()\n",
    "        resume = normalize(resume)\n",
    "        data.loc[len(data)] = [x[:-4], job, resume]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ardiela Dramat</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeanine Adant</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joan Nicolene Esterhuizen</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rozina Scheepers</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samantha Jennings</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[information, concerning, candidate, furnished...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sonja Krog</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surelda Schlebusch</td>\n",
       "      <td>administration manager</td>\n",
       "      <td>[position, applied, new, business, sales, cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gwendolene Margaret Matjan</td>\n",
       "      <td>assistant accountant</td>\n",
       "      <td>[pdf15, one, zero, obj, typecatalogpages, two,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hallesheen Leshae Moos</td>\n",
       "      <td>assistant accountant</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Luan Benjamin</td>\n",
       "      <td>assistant accountant</td>\n",
       "      <td>[confidentiality, clause, information, concern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               candidate_name               job_title  \\\n",
       "0              Ardiela Dramat  administration manager   \n",
       "1               Jeanine Adant  administration manager   \n",
       "2   Joan Nicolene Esterhuizen  administration manager   \n",
       "3            Rozina Scheepers  administration manager   \n",
       "4           Samantha Jennings  administration manager   \n",
       "5                  Sonja Krog  administration manager   \n",
       "6          Surelda Schlebusch  administration manager   \n",
       "7  Gwendolene Margaret Matjan    assistant accountant   \n",
       "8      Hallesheen Leshae Moos    assistant accountant   \n",
       "9               Luan Benjamin    assistant accountant   \n",
       "\n",
       "                                              resume  \n",
       "0  [confidentiality, clause, information, concern...  \n",
       "1  [confidentiality, clause, information, concern...  \n",
       "2  [confidentiality, clause, information, concern...  \n",
       "3  [confidentiality, clause, information, concern...  \n",
       "4  [information, concerning, candidate, furnished...  \n",
       "5  [confidentiality, clause, information, concern...  \n",
       "6  [position, applied, new, business, sales, cros...  \n",
       "7  [pdf15, one, zero, obj, typecatalogpages, two,...  \n",
       "8  [confidentiality, clause, information, concern...  \n",
       "9  [confidentiality, clause, information, concern...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('resume_challenge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
